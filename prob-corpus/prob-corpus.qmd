---
title: "Training a classifier with a probabilistic data set:"
subtitle: "Discrete and weighted training with Bayes and maximum likelihood"
author: "Bob Carpenter"
date: "last-modified"
jupyter: python3
filters:
    - include-code-files
format:
  html:
    theme: cosmo
    css: style.css
    highlight-style: atom-one
    mainfont: Palatino
    fontcolor: black
    monobackgroundcolor: white
    monofont: "Menlo, Lucida Console, Liberation Mono, DejaVu Sans Mono, Bitstream Vera Sans Mono, Courier New, monospace"
    fontsize: 13pt
    linestretch: 1.4
    number-sections: true
    number-depth: 2
    toc: true
    toc-location: right
    cap-location: bottom
    format-links: false
    embed-resources: true
    anchor-sections: true
  pdf:
    include-in-header:
      - file: header.tex
    mainfont: Palatino
    number-sections: true
    number-depth: 2
    margin-bottom: 1in
    fig-pos: "t!"
    biblio-title: "References"
    biblio-style: natbib
    link-citations: true
    link-bibliography: true
    pdf-engine: xelatex
    highlight-style: github
bibliography: references.bib
---

# Introduction

This short technical note lays out several approaches to training a
classifier when the probability of each item's outcome is known. The
motivating example is the probability assigned by a model of data
rating (also known as coding, annotation, labeling, and crowdsourcing),
such as that of @dawid1979.

This note presents two results.  The first result is that when
creating a corpus, it is more effective to sample the category for
each item given its probability distribution than it is to assign it
the most probable category. Approaches to crowdsourcing using a
majority vote approach are instances of the suboptimal most-probable
strategy.

The second result is that it is even better to use the category
probabilities directly.  This is a direct consequence of the
Rao-Blackwell theorem in the Bayesian setting.

These results hold for both Bayesian posterior mean estimators and the
penalized maximum likelihood estimators.  The Bayesian posterior mean
estimator minimizes expected square error, which is borne out
experimentally when the data is generated probabilistically according
to the generative model or weighted logistic regression training is
used.  Under the other data generation regimes, the results are
indistinguishable.


# Logistic regression

Logistic regression applies in the situation where there are $N$
binary observations $y_n \in \{ 0, 1 \}$ and each observation
comes with a (row) vector $x_n \in \mathbb{R}^D$ of covariates (also called
features or predictors).  Logistic regression is a generalized linear
model, with a parameter vector $\beta \in \mathbb{R}^D$ of
regression coefficients (also called weights), the link function is
log odds (also known as logit), and the family is binomial, so the
sampling distribution is
$$
Y_n \sim \textrm{binomial}(\textrm{logit}^{-1}(x_n \cdot \beta)),
$$
where $\textrm{logit}:(0, 1) \rightarrow \mathbb{R}$ and its inverse
$\textrm{logit}^{-1}:\mathbb{R} \rightarrow (0, 1)$ are defined by
$$
\textrm{logit}(u) = \log \frac{u}{1 - u}
\qquad
\textrm{logit}^{-1}(v) = \frac{1}{1 + \exp(-v)}.
$$
The definition of the binomial distribution implies
$$
\Pr[Y_n = 1] = \textrm{logit}^{-1}(x_n \cdot \beta).
$$

# Data simulation

For simplicity, we will simulate our parameter vector $\beta \in
\mathbb{R}^D$ as standard normal,
$$
\beta \sim \textrm{normal}(0, 1).
$$

Given a data size $N$, we generate a covariate matrix $x \in
\mathbb{R}^{N \times D}$ by taking
$$
x_n \sim \textrm{multi-normal}(0, \Sigma),
$$
where $\Sigma \in \mathbb{R}^{D \times D}$ is a full rank covariance
matrix (i.e., it is symmetric and positive definite).  We consider two
choices of covariance matrix.  First, we take the identity matrix $I$,
so that the covariates are generated as standard normal.  Second, we
will generate a covariance matrix corresponding to a first order
random walk, which will lead to highly correlated
predictors, as is often seen in practical applications in biomedicine,
social science, and machine learning.  The random-walk covariance
matrix is defined for a correlation value $\rho \in (-1, 1)$ by
$$
\Sigma_{i, j} = \rho^{| i - j |}.
$$
For example, with $D = 20$ and $\rho = 0.9$, the first row of the
covariance matrix is
$$
\Sigma_{1, 1:20} =
\begin{bmatrix}
1.00 & 0.90 & 0.81 & 0.73 & 0.66 & \cdots & 0.19 & 0.17 & 0.15 & 0.14
& 0.12
\end{bmatrix}.
$$

## Follow the data generating process

We can now simulate outcomes $Y_n$ in two different ways.  According
to the true data generating process, this should be done by sampling
$$
Y_n \sim \textrm{binomial}(\textrm{logit}^{-1}(x_n \cdot \beta).
$$

## Choose the most probable outcome

We can take the most probable outcome, by setting
A common approach in machine learning to deal with crowdsourcing with
multiple data coders is to take a majority vote or by the most
probable outcome in the probabilistic model.  This corresponds to
setting
$$
Y_n =
\begin{cases}
1 & \textrm{if } \Pr[Y_n = 1 \mid X_n = x_n] > \frac{1}{2}, \textrm{
and}
\\[4pt]
0 & \textnormal{otherwise}.
\end{cases}
$$
The name $Y_n$ is the same as in the previous section, but this is a
different random variable that is used as an alternative to the
previous definition (hence the same notation).

## Outcome probabilities

Rather than setting a single value for $Y_n$, we use the probability
estimates directly to train.  Here, we will assume the data consists
of outcome probabilities
$$
p_n = \Pr[Y_n = 1 \mid X_n = x_n].
$$
With direct probability estimates, we will be able to train using a
weighted logistic regression or with linear regression through a log
odds transform. 

# Priors, penalties, and objectives

## Bayesian prior

To complete our Bayesian model, which is a joint probability function
$p(y, \beta),$ we take independent standard normal priors for the
coefficients $d \in 1{:}D,$
$$
\beta_d \sim \textrm{normal}(0, 1).
$$
This prior matches our data generating process so that our model is
well specified for the data.

The full joint Bayesian model is defined by combining the prior and
sampling distributions, to give us the mixed continuous/discrete
probability function 
\begin{align}
p(y, \beta)
&= p(y \mid \beta) \cdot p(\beta).
\\[4pt]
&= \prod_{n=1}^N \textrm{bernoulli}(y_n \mid \textrm{logit}^{-1}(x_n \cdot
\beta))
\cdot \prod_{d=1}^D \textrm{normal}(\beta_d \mid 0, 1).
\end{align}

The objective for Bayesian estimation is the posterior distribution,
which has the following conditional density function (up to a proportion),
$$
p(\beta \mid y) \propto p(y \mid \beta) \cdot p(\beta).
$$
We use the notation $g$ to indicate that it is an unnormalized density.
We integrate over the objective function to perform Bayesian
inference.

## Frequentist penalty function

From the frequentist perspective, we have a log likelihood function for
the data $(x, y)$ defined as a function of parameters $\beta,$
\begin{align}
\mathcal{L}(\beta)
&= \log \left( \prod_{n=1}^N \textrm{bernoulli}(y_n \mid \textrm{logit}^{-1}(x_n
\cdot \beta)) \right)
\\[4pt]
&= \sum_{n=1}^N \log \textrm{bernoulli}(y_n \mid \textrm{logit}^{-1}(x_n \cdot \beta)).
\end{align}

We will evaluate penalized maximum likelihood, where we will use the
penalty function
$$
\mathcal{P}(\beta) = \frac{1}{2} \beta^\top \beta.
$$
This penalty is called an L2 penalty because it's based on the (half
of the squared) L2-norm of $\beta$.  Using an L2 penalty function for
penalized maximum likelihood estimation is known as ridge regression.
The L2 penalty shrinks estimates toward zero by penalizing the
components of $\beta$ quadratically.

The objective function for frequentist estimation is known as the
penalized maximum likelihood function and is defined by
$$
\mathcal{F}(\beta) = \mathcal{L}(\beta) - \mathcal{P}(\beta).
$$
Frequentist estimation proceeds by optimization over the objective.

## Frequentist and Bayesian objectives are the same

The frequentist objective function is just the log posterior plus a
constant,
$$
\mathcal{F}(\beta) = \log p(\beta \mid y) + \textrm{const}.
$$
The constant, which we will not need to carry out Bayesian inference,
is $\log p(y).$

This relation does not imply that the Bayesian and frequentist
estimates will be the same.  Full Bayesian inference will average
over uncertainty rather than optimize.

# Estimation

For each observation $n \in 1{:}N,$ we have the covariate vector $x_n
\in \mathbb{R}^D$.

## Estimation from training data

The first two cases of simulation, sampling from the data generating
process and assigning the most probable category involve data $y_n \in
\{ 0, 1 \}$ for $n \in 1{:}N.$

### Bayesian estimate from training data

Given a data set $(x, y),$ the Bayesian parameter estimate is the posterior mean,
\begin{align}
\widehat{\beta}
&= \mathbb{E}[\beta \mid x, y]
\\[4pt]
&= \int_{\mathbb{R}^D} \beta \cdot p(\beta \mid x, y) \, \textrm{d}\beta.
\end{align}
We can use Markov chain Monte Carlo methods to take a sample
$$
\beta^{(1)}, \ldots, \beta^{(M)} \sim p(\beta \mid x, y),
$$
and estimate
$$
\widehat{\beta}
\approx
\frac{1}{M} \sum_{m=1}^M \beta^{(m)}.
$$
As $M \rightarrow \infty,$ the Monte Carlo approximation becomes exact
in the limit.  With $M = 10,000,$ we usually have around 2 digits of accuracy.


### Frequentist estimate from data

The frequentist estimate is the penalized maximum likelihood estimate,
$$
\beta^* = \textrm{arg max}_\beta \ \textrm{F}(\beta).
$$
Because of the relation between the Bayesian and frequentist
objectives for this problem, this estimate is also called the maximum
a posterior estimate because
$$
\beta^* = \textrm{arg max}_\beta \ p(\beta \mid x, y)
$$

## Probability-weighted estimation

In probability weighted training, we modify the objective function so
the data consists of weights $p_n \in (0, 1)$ for outcomes $n \in
1{:}N.$

### Bayesian objective

The Bayesian objective is defined by weighting the outcomes probabilistically,
$$
p(\beta \mid x, p)
\propto p(\beta)
        \cdot \prod_{n=1}^N
	       \left( \strut p(Y_n = 1 \mid x_n, \beta)^{p_n}
                      \cdot p(Y_n = 0 \mid x_n, \beta)^{1 - p_n} \right),
$$
which on the log scale is
$$
\log p(\beta \mid x, p)
= \log p(\beta)
  + \sum_{n=1}^N \left( \strut p_n \log p(Y_n = 1 \mid x_n, \beta)
                        + (1 - p_n) \log p(Y_n = 0 \mid x_n, \beta) \right)
  + \textrm{const}.
$$

This objective is known as the Rao-Blackwellized form of our original
objective.  The Rao-Blackwell theorem entails that working in
expectation, as we are doing here, perfroms no worse than sampling in
terms of estimation error; in practice, Rao-Blackwellizing usually
brings substantial gains, especially in the context of discrete
sampling as we are doing here.

For estimation, we use posterior means as before, swapping in this
objective for the previous one.

### Frequentist objective

The frequentist objective here mirrors the Bayesian objective,
$$
\mathcal{F}(\beta)
= + \sum_{n=1}^N \left( \strut p_n \log p(Y_n = 1 \mid x_n, \beta)
                        + (1 - p_n) \log p(Y_n = 0 \mid x_n, \beta)
			\right)
  - \frac{1}{2}\beta^2.
$$  
For estimation, we optimize this objective.


## Regression on the log odds

The final estimation technique involves recognizing that when working
in expectation, the log odds link function can be used to transform
the probabilistic data to the log odds scale, at which point
estimation can proceed via linear regression.  Because the location
and scale parameters in a linear regression are conditionally
independent given the data, we just fix the scale parameter to unity.

### Bayesian regression on log odds

The Bayesian objective function is defined by the data generating
process
$$
\textrm{logit}(p_n) \sim \textrm{normal}(x_n \cdot \beta, 1),
$$
which leads to the objective function
$$
p(\beta \mid x, p)
\propto \left( \prod_{d=1}^D \textrm{normal}(\beta_d \mid 0, 1) \right)
  \cdot \prod_{n=1}^N \textrm{normal}(\textrm{logit}(p_n) \mid x_n \cdot \beta, 1).
$$
On the log scale, that's
$$
\log p(\beta \mid x, p)
= \left( \sum_{d=1}^D \log \textrm{normal}(\beta_d \mid 0, 1) \right)
  + \sum_{n = 1}^N \log \textrm{normal}(\textrm{logit}(p_n) \mid x_n
  \cdot \beta, 1)
  + \textrm{const}.
$$  

For estimation, we use posterior means as before, swapping in this
objective for the previous one.

### Frequentist regression on log odds

The frequentist objective function is the same up to a constant,
$$
\mathcal{F}(\beta)
=  \left( \sum_{n=1}^N \log \textrm{normal}(\textrm{logit}(p_n) \mid
x_n \cdot \beta, 1) \right)
- \frac{1}{2} \beta^\top \cdot \beta.
$$
For estimation, we use optimization on the objective function.


# Predictive inference

After fitting a logistic regression modle, it may be used for
prediction.  Specifically, it can be used to transform a vector of
covariates for a new item to a probabilistic prediction of its
category.

## Bayesian posterior predictive inference

Suppose the training data is a sequence of pairs $(x_n, y_n)$ where
$x_n \in \mathbb{R}^D$ and $y_n \in \{ 0, 1 \}$ for $n \in 1{:}N,$ and
$\beta \in \mathbb{R}^D.$
Now suppose there are new items with covariates $\widetilde{x}_n$ for
$n \in 1{:}\widetilde{N}.$  For each new covariate vector $\widetilde{x}_n,$ the
prediction for an outcome $\widetilde{y}_n \in \{ 0, 1 \}$ is given by
the posterior predictive probability mass function,
\begin{align*}
p(\widetilde{y} \mid \widetilde{x}, x, y)
&= \mathbb{E}\!\left[\widetilde{Y} \,\big|\, \widetilde{x}, x, y\right]
\\[4pt]
&= \int_{\mathbb{R}^D} p(\widetilde{y} \mid \widetilde{x}, \beta) \cdot p(\beta \mid
x, y) \ \textrm{d}\beta.
\end{align*}

With a sample of MCMC draws
$$
\beta^{(1)}, \ldots, \beta^{(M)} \sim p(\beta \mid x, y)
$$
for $m \in 1{:}M,$ this quantity can be estimated as
$$
p(\widetilde{y} \mid \widetilde{x}, x, y)
\approx
\frac{1}{M} \sum_{m = 1}^M p\!\left(\widetilde{y} \,\big|\, \widetilde{x}, 
\beta^{(m)}\right).
$$

Because of issues with floating-point numbers on computers, we have to
guard against underflow in density functions.  Instead of calculating
$p(\widetilde{y} \mid \widetilde{x}, \beta^{(m)}),$
we instead calculate
$\log p(\widetilde{y} \mid, \widetilde{x}, \beta^{(m)}),$
which allows us to calculate the final result on the log scale as
\begin{align*}
\log p(\widetilde{y} \mid \widetilde{x}, x, y)
&\approx
\log \frac{1}{M} \sum_{m = 1}^M p\!\left(\widetilde{y} \,\big|\, \widetilde{x}, 
\beta^{(m)}\right)
\\[4pt]
&= -\log M + \log \sum_{m = 1}^M p\!\left(\widetilde{y} \,\big|\, \widetilde{x}, 
\beta^{(m)}\right)
\\[4pt]
&= -\log M + \log \sum_{m = 1}^M \exp\!\left(\log \ p\!\left(\widetilde{y} \,\big|\, \widetilde{x}, 
\beta^{(m)}\right)\right)
\\[4pt]
&= -\log M + \textrm{logSumExp}_{m=1}^M \log \ p\!\left(\widetilde{y} \,\big|\, \widetilde{x}, 
\beta^{(m)}\right).
\end{align*}

The log-sum-of-exponentials function can be implemented in an
arithmetically stable way for a vector $v \in \mathbb{R}^M$ as
\begin{align*}
\textrm{logSumExp}_{m=1}^M v_m
&= \log \sum_{m = 1}^M \ \exp(v_m)
\\
&= \max(v) + \log \sum_{j=1}^K \exp(v_j - \max(v)).
\end{align*}
The stability follows from never applying $\exp()$ to a positive
number combined with pulling the leading digits out with $\max(v).$

We will be reporting an estimate of the expected log posterior density
per item, which for $y \in \{0, 1\}^N$ is 
$$
\textrm{ELPD} = \frac{\log p(\widetilde{y} \mid \widetilde{x}, x, y)}
                     {\widetilde{N}}.
$$		     


## Frequentist plug-in inference

Standard practice in machine learning fits a penalized maximum
likelihood estimate
$$
\beta^*
= \textrm{arg max}_\beta \
  \log p(y \mid x, \beta) - \mathcal{P}(\beta),
$$
which is plugged in for prediction,
$$
p(\widetilde{y} \mid \widetilde{x}, x, y)
\approx
p(\widetilde{y} \mid \widetilde{x}, \beta^*).
$$

# Simulation-based evaluation

## Stan models

There are three objective functions in play, based on whether the data
under consideration is given as discrete outcomes $y_n$ or
probabilities $p_n$, and in the case of probabilities, whether they
are transformed to log odds for a linear regression.  

### Stan program for logistic regression

The Stan program for logistic regression implements the following log
posterior up to an additive constant, 
$$
\log p(\beta \mid x, y)
= \log p(\beta)
  + \sum_{n=1}^N \textrm{bernoulli}(\textrm{logit}^{-1}(x_n \cdot
  \beta)).
$$  

```{.stan include="logistic-regression.stan"
          filename="logistic-regression.stan"}
```


### Stan program for probability-weighted logistic regression

The Stan program for probability-weighted logistic regression
implements the following log posterior up to an additive constant,
$$
\log p(\beta \mid x, p)
= \log p(\beta)
  + \sum_{n=1}^N \left(
      \begin{array}{l}
      p_n \cdot \log \textrm{bernoulli}(1 \mid \textrm{logit}^{-1}(x_n \cdot \beta))
      \\[2pt]
      \ + (1 - p_n) \cdot \textrm{bernoulli}(0 \mid
      \textrm{logit}^{-1}(x_n \cdot \beta)) 
    \end{array}
    \right)
  + \textrm{const}.
$$

```{.stan include="weighted-logistic-regression.stan"
          filename="weighted-logistic-regression.stan"}
```

### Stan program for log odds linear regression

The Stan program for linear regression on the log odds implements the
following log posterior up to an additive constant.
$$
\log p(\beta \mid x, p)
= \log p(\beta)
  + \sum_{n = 1}^N
    \log \textrm{normal}(\textrm{logit}(p_n) \mid x_n \cdot \beta, 1)
  + \textrm{const}.
$$

```{.stan include="log-odds-linear-regression.stan"
          filename="log-odds-linear-regression.stan"}
```


## Evaluation of estimation

The evaluation is coded in Python using the CmdStanPy interface to
Stan using NumPy, pandas, and plotnine.   The first step is to import
these libraries, configure logger to only report errors, and set a
random seed for NumPy.

```{python}
#| code-fold: true
import logging
import scipy as sp
import numpy as np
import pandas as pd
import plotnine as pn
import cmdstanpy as csp
csp.utils.get_logger().setLevel(logging.ERROR)  # only log errors

np.random.seed(12345)   # change seed for fresh simulation
```

Second, define functions to use later.

```{python}
def rw_cov_matrix(D, rho):
    Sigma = np.zeros((D, D))
    for i in range(D):
        for j in range(D):
            Sigma[i, j] = rho ** abs(i - j)
    return Sigma

def random_predictors(N, D, rho):
    Sigma = rw_cov_matrix(D, rho)
    mu = np.zeros(D)
    x = np.random.multivariate_normal(mu, Sigma, N)
    for n in range(N):
        x[n, 1] = 1.0  # intercept
    return x
    
def sq_error(u, v):
    return sum((u - v)**2)

def fit_bayes(model, data_dict):
    return model.sample(data = data_dict, show_progress = False,
                        show_console = False, seed=12345, inits = 0)

def fit_bayes_draws(model, data_dict):
    fit = fit_bayes(model, data_dict)
    return fit.stan_variable("beta")

def fit_mle(model, data_dict):
    mle = model.optimize(data = data_dict, show_console = False, seed=12345)
    return mle.stan_variable("beta")

def elpd(test_data, fit, model_predict):
    lp_draws_max = model_predict.generate_quantities(data = test_data, previous_fit = fit,
                                                     show_console = False, seed = 12345)
    return sp.special.logsumexp(lp_draws_max.stan_variable("log_p")) / test_data['y'].size

def inv_logit(x):
    return 1 / (1 + exp(-x))

def add_row(df, beta_hat, beta, estimator, data):
    return pd.concat([df, pd.DataFrame({'error': (sq_error(beta_hat, beta), ),
                                        'estimator': (estimator, ),
                                        'data': (data, )})],
                         ignore_index=True)

def add_elpd(df, elpd, estimator, data):
    return pd.concat([df, pd.DataFrame({'error': (elpd, ),
                                        'estimator': (estimator, ),
                                        'data': (data, )})],
                         ignore_index=True)
```


Third, compile the Stan programs introduced in the previous section.

```{python}
model_logistic = csp.CmdStanModel(stan_file = "logistic-regression.stan")
model_weighted_logistic = csp.CmdStanModel(stan_file = "weighted-logistic-regression.stan")
model_log_odds_linear = csp.CmdStanModel(stan_file = "log-odds-linear-regression.stan")
model_predict = csp.CmdStanModel(stan_file = "logistic-regression-predict.stan")
```

Fourth, set all the constants determining sizes for the simulation.

```{python}
D = 21        # number of predictors including intercept
N = 200       # number of data points used to train
rho = 0.9     # correlation of predictor RW covariance
N_test = 500  # number of test items
M = 100        # number of simulation runs
```

Fifth, allocate a pandas data frame to store the results, then collect
results `M` iterations.  Within each iteration, generate predictors
and the various outcomes randomly.  For each of these, calculate the
penalized MLE and Bayesian posterior mean and add them to the data frame.

```{python}
def inv_logit(u):
    return 1 / (1 + np.exp(-u))

df = pd.DataFrame({'error': (), 'estimator': (), 'data': ()})
for m in range(M):
    # parameter generation
    beta = np.random.normal(0, 1, D)

    # Training data generation
    x = random_predictors(N, D, rho)
    E_log_odds = np.dot(x, beta)
    E_y = inv_logit(E_log_odds)
    y_max = np.where(E_y > 0.5, 1, 0)
    y_random = np.random.binomial(n=1, p=E_y)
    p = E_y
    y_noisy_log_odds = E_log_odds + np.random.normal(0, 1, N)
    noisy_p = inv_logit(y_noisy_log_odds)
    data_max = {'D': D, 'N': N, 'x': x, 'y': y_max }
    data_random = {'D': D, 'N': N, 'x': x, 'y': y_random }
    data_probs = {'D': D, 'N': N, 'x': x, 'p': p }
    data_noisy_weights = {'D': D, 'N': N, 'x': x, 'p': noisy_p}

    # Penalized MLE
    mle_max = fit_mle(model_logistic, data_max)
    mle_random = fit_mle(model_logistic, data_random)
    mle_probs = fit_mle(model_weighted_logistic, data_probs)
    mle_weights = fit_mle(model_log_odds_linear, data_probs)
    mle_noisy = fit_mle(model_log_odds_linear, data_noisy_weights)
    df = add_row(df, mle_max, beta, "MLE", "most probable")        
    df = add_row(df, mle_random, beta, "MLE", "random")        
    df = add_row(df, mle_probs, beta, "MLE", "weighted")        
    df = add_row(df, mle_weights, beta, "MLE", "log odds")
    df = add_row(df, mle_noisy, beta, "MLE", "noisy log odds")        

    # Bayesian
    beta_draws_max = fit_bayes_draws(model_logistic, data_max)
    beta_draws_random = fit_bayes_draws(model_logistic, data_random)
    beta_draws_probs = fit_bayes_draws(model_weighted_logistic, data_probs)
    beta_draws_weights = fit_bayes_draws(model_log_odds_linear, data_probs)
    beta_draws_noisy_weights = fit_bayes_draws(model_log_odds_linear, data_noisy_weights)
    mean_max = np.zeros(D)
    mean_random = np.zeros(D)
    mean_probs = np.zeros(D)
    mean_weights = np.zeros(D)
    mean_noisy = np.zeros(D)
    for d in range(D):
        mean_max[d] = np.mean(beta_draws_max[:, d])
        mean_random[d] = np.mean(beta_draws_random[:, d])
        mean_probs[d] = np.mean(beta_draws_probs[:, d])
        mean_weights[d] = np.mean(beta_draws_weights[:, d])
        mean_noisy[d] = np.mean(beta_draws_noisy_weights[:, d])
    df = add_row(df, mean_max, beta, "Bayes", "most probable")        
    df = add_row(df, mean_random, beta, "Bayes", "random")        
    df = add_row(df, mean_probs, beta, "Bayes", "weighted")        
    df = add_row(df, mean_weights, beta, "Bayes", "log odds")        
    df = add_row(df, mean_noisy, beta, "Bayes", "noisy log odds")
```

Finally, print the results as a table with a custom reporter for
means, 0.1, 0.5 (median), 0.9 quantiles, and the minimum and maximum,
rounding to a single decimal place.

```{python}
def summary(x):
    return pd.Series({
        'mean': np.mean(x),
        '10%': np.quantile(x, 0.1),
        'median': np.quantile(x, 0.5),
        '90%': np.quantile(x, 0.9),
        'min': np.min(x),
        'max': np.max(x)
    })

summary_table = df.groupby(['estimator','data'])['error'].apply(summary).unstack()
print(summary_table.round(1))
```

The results can also be presented via histograms faceted by data type
and estimator.

```{python}
plot = (pn.ggplot(df, pn.aes(x = 'error'))
    + pn.geom_histogram(bins = 10, color='white', size=0.1)
    + pn.facet_grid('estimator ~ data', scales="free_x")
    + pn.scale_x_log10())
print(plot)
```

The simulations clearly show that training with logit-transformed
probabilities is the most effective, followed by noisy
logit-transformed probabilities and weighted training, followed by
random sampling, and finally, far behind, taking the most probable
category.

The penalized maximum likelihood estimator is better at handling the
most probable category sampling, but is otherwise similar or slightly
trails the Bayesian estimator.


## Evaluation of predictive inference

For evaluation of both fully Bayesian and plug-in inference, the
followin Stan model suffices.

```{.stan include="logistic-regression-predict.stan"
          filename="logistic-regression-predict.stan"}
```

The data includes both the test covariates and the test outcomes.  The
parameters are the same as in the models for training.  For predictive
inference, the model block is replaced with a generated quantities
block that assigns the log density of the data given the parameters to
the variable `log_p_t`.

The evaluation follows the earlier evaluation, only we now measure
predictive accuracy rather than estimation accuracy.  

```{python}
df_predict = pd.DataFrame({'error': (), 'estimator': (), 'data': ()})
for m in range(M):
    beta = np.random.normal(0, 1, D)

    # Training data generation
    x = random_predictors(N, D, rho)
    E_log_odds = np.dot(x, beta)
    E_y = inv_logit(E_log_odds)
    y_max = np.where(E_y > 0.5, 1, 0)
    y_random = np.random.binomial(n=1, p=E_y)
    noisy_E_log_odds = E_log_odds + np.random.normal(0, 1, N)
    noisy_E_y = inv_logit(noisy_E_log_odds)
    data_max = {'D': D, 'N': N, 'x': x, 'y': y_max }
    data_random = {'D': D, 'N': N, 'x': x, 'y': y_random }
    data_probs = {'D': D, 'N': N, 'x': x, 'p': E_y }
    data_noisy_weights = {'D': D, 'N': N, 'x': x, 'p': noisy_E_y}

    # Test data generation
    x_test = random_predictors(N_test, D, rho)
    E_y_test = inv_logit(np.dot(x_test, beta))
    y_test = np.random.binomial(n = 1, p = E_y_test)

    # Penalized MLE fit
    mle_max = fit_mle(model_logistic, data_max)
    mle_random = fit_mle(model_logistic, data_random)
    mle_probs = fit_mle(model_weighted_logistic, data_probs)
    mle_weights = fit_mle(model_log_odds_linear, data_probs)
    mle_noisy = fit_mle(model_log_odds_linear, data_noisy_weights)

    # Penalized MLE prediction
    lp_mle_max = sp.stats.bernoulli.logpmf(y_test, inv_logit(np.dot(x_test, mle_max))).sum()
    lp_mle_random = sp.stats.bernoulli.logpmf(y_test,  inv_logit(np.dot(x_test, mle_random))).sum()
    lp_mle_probs = sp.stats.bernoulli.logpmf(y_test, inv_logit(np.dot(x_test, mle_probs))).sum()
    lp_mle_weights = sp.stats.bernoulli.logpmf(y_test, inv_logit(np.dot(x_test, mle_weights))).sum()
    lp_mle_noisy_weights = sp.stats.bernoulli.logpmf(y_test, inv_logit(np.dot(x_test, mle_noisy))).sum()

    log_Pr_rate_max = lp_mle_max / N_test
    log_Pr_rate_random = lp_mle_random / N_test
    log_Pr_rate_probs = lp_mle_probs / N_test
    log_Pr_rate_weights = lp_mle_weights / N_test
    log_Pr_rate_noisy_weights = lp_mle_noisy_weights / N_test

    df_predict = add_elpd(df_predict, log_Pr_rate_max, "MLE", "most probable")
    df_predict = add_elpd(df_predict, log_Pr_rate_random, "MLE", "random")
    df_predict = add_elpd(df_predict, log_Pr_rate_probs, "MLE", "weighted")
    df_predict = add_elpd(df_predict, log_Pr_rate_weights, "MLE", "log odds")
    df_predict = add_elpd(df_predict, log_Pr_rate_noisy_weights, "MLE", "noisy log odds")

    # Bayesian fit
    fit_max = fit_bayes(model_logistic, data_max)
    fit_random = fit_bayes(model_logistic, data_random)
    fit_probs = fit_bayes(model_weighted_logistic, data_probs)
    fit_weights = fit_bayes(model_log_odds_linear, data_probs)
    fit_noisy_weights = fit_bayes(model_log_odds_linear, data_noisy_weights)

    # Bayesian prediction
    test_data = {'D': D, 'N': N_test, 'x': x_test, 'y': y_test}
    elpd_max = elpd(test_data, fit_max, model_predict)
    elpd_random = elpd(test_data, fit_random, model_predict)
    elpd_probs = elpd(test_data, fit_probs, model_predict)
    elpd_weights = elpd(test_data, fit_weights, model_predict)
    elpd_noisy_weights = elpd(test_data, fit_noisy_weights, model_predict)
    df_predict = add_elpd(df_predict, elpd_max, "Bayes", "most probable")
    df_predict = add_elpd(df_predict, elpd_random, "Bayes", "random")
    df_predict = add_elpd(df_predict, elpd_probs, "Bayes", "weighted")
    df_predict = add_elpd(df_predict, elpd_weights, "Bayes", "log odds")
    df_predict = add_elpd(df_predict, elpd_noisy_weights, "Bayes", "noisy log odds")
```

After building up the results, we can summarize the results using a
pandas one-liner.

```{python}
# pd.set_option('display.max_rows', None)
# print(df_predict)
summary_table_predict = df_predict.groupby(['estimator','data'])['error'].apply(summary).unstack()
print(summary_table_predict.round(2))
```

# Further reading

The Stan *Reference Manual,* by the @stan2023, describes the Stan
programming language.  The *User's Guide,* by the @stan2023b,
describes how to use the Stan language to code statistical models,
including both hierarchical logistic regression and the Dawid and
Skene crowdsourcing model.

@dawid1979 first modeled crowdsourcing as noisy raters providing
measurements conditioned on the true value.  In a binary task, each
rater's sensitivity and specificity is estimated, as is the prevalence
of successful (1) outcomes, which allows a probabilistic assignment of
category to each item.  It is straightforward to extend Dawid and
Skene's model to a Bayesian hierarchical model as shown by @paun2018
and in the "Latent discrete parameters" chapter of the *Stan User's
Guide.*  There is a rich literature on similar models in epidemiology,
educational testing, and sociology.

@smyth1994 is he first example of which I'm aware of jointly training
a classifier and a crowdsourcing model.  @raykar2010 performs joint
training in a logistic regression setting using Dawid and Skene's
model.  

@passonneau2014 provide a high-level motivation for rating models over
weighted voting approaches and inter-annotator agreement measures and
include an analysis of a large-scale open-access data set (1M ratings).
It also describes how the model handles spammy and adversarial
annotators, discusses identifiability issues, and suggests a method of
active learning based on the model.  Even with 20 raters per item,
the ratings of some items did not converge, which further motivates
the use of probabilistic training.

@gneiting2007 and @gneiting2007b provide an excellent overview of
proper scoring metrics and calibrated prediction, respectively.


# Conclusions

If you have a data set with probabilistic labels, the best thing to do
is to train with those probabilities.  In the case of logistic
regression, you can go one step better by log odds transforming the
probabilities and directly training a linear regression.  If you are
restricted to estimation (training) software that can only handle
deterministic categories, then the best thing to do is to sample the
categories randomly given the probabilities.  Whatever you do, do not
take the most probable category or use majority voting for
crowdsourcing.

### Appendix: System settings

The system and operating system are as follows.
```{python}
import sys
import platform

print("\nSystem")
print(sys.version)

print("\nOperating System")
print(f"""  {platform.system() = }
  {platform.release() = }
  {platform.version() = }""")
```

The installed packages (i.e., the working set) is as follows.
```{python}
import pkg_resources

print("\nInstalled packages:")
for dist in pkg_resources.working_set:
    print(dist)
```


```