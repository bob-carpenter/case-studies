---
title: "Combining Rating and Ranking:"
subtitle: "Plackett-Luce ranking and ordinal logit rating models in Stan"
author: "Bob Carpenter"
date: "last-modified"
jupyter: python3    
filters:
    - include-code-files
format:
  html:
    theme: cosmo
    css: style.css
    highlight-style: atom-one
    mainfont: Palatino
    fontcolor: black
    monobackgroundcolor: white
    monofont: "Menlo, Lucida Console, Liberation Mono, DejaVu Sans Mono, Bitstream Vera Sans Mono, Courier New, monospace"
    fontsize: 13pt
    linestretch: 1.4
    number-sections: true
    number-depth: 2
    toc: true
    toc-location: right
    code-fold: false
    code-copy: true
    cap-location: bottom
    format-links: false
    embed-resources: true
    anchor-sections: true
  pdf:
    include-in-header:
      - file: header.tex
    mainfont: Palatino
    number-sections: true
    number-depth: 2
    margin-bottom: 1in
    fig-pos: "t!"
    biblio-title: "References"
    biblio-style: natbib
    link-citations: true
    link-bibliography: true
    pdf-engine: xelatex
    highlight-style: github
bibliography: references.bib
---

# Preface {.unnumbered}

We will first load all of the libraries in Python that we will need

```python
import urllib.request
import zipfile
import os
import numpy as np
import pandas as pd
import cmdstanpy as csp
```

We do not have permission to redistribute the data with our case
study, so we will download it and unzip it into a top-level directory
`sushi3-2016`.

```python
url = "https://www.kamishima.net/asset/sushi3-2016.zip"
download_path = "sushi3-2016.zip"
output_dir = "./"
if not os.path.isdir(output_dir):
    os.makedirs(output_dir, exist_ok=True)
    urllib.request.urlretrieve(url, download_path)
    with zipfile.ZipFile(download_path, 'r') as zip_ref:
        zip_ref.extractall(output_dir)
```


# Introduction

In this case study, we will develop two standard models of preference
data, the Plackett-Luce model of ranking and the ordinal logistic
model of rating.  We will further combine them into a single model
with a likelihood for each data stream.

## The data

Toshihiro Kamishima collected data from $R = 5000$ Japanese raters about
their preferences for sushi and made it available:

* [Sushi Preference data set](https://www.kamishima.net/sushi/)

For each of these sushi raters, they collected preference data for 10
types of sushi selected at random from a total collection of 100 types
of sushi.  Each rater provided two types of information,

* rank ordering of 10 pieces of sushi
* ordinal ratings on a 1--5 scale of the pieces of sushi (5 being
* better) 


```
df = pd.read_csv('sushi3-2016/sushi3b.5000.10.order',
                     delim_whitespace=True, header=None, skiprows=1)
df = df.drop(columns=[0, 1])
y = df.to_numpy()
y = y + 1   # data indexes items from 0
y = y.astype(int)
rev_row_y = y[::-1]  
data_dict = {'I': 100, 'R': 5000, 'K': 10, 'y': rev_row_y }

model = csp.CmdStanModel(stan_file = 'plackett-luce.stan')
fit = model.sample(data = data_dict, chains = 4, parallel_chains=4, show_console = True,
                       refresh=20, iter_warmup = 500, iter_sampling=500)

df_items = pd.read_csv('sushi3-2016/sushi3.idata',
                           delim_whitespace=True, header=None)
item_names = df_items.iloc[:, 1].values
item_scores = [np.mean(fit.stan_variable('alpha')[:,i]) for i in range(100)]
df_out = pd.DataFrame({'type': item_names, 'score': item_scores})
df_out.sort_values(by='score', ascending=False, inplace=True)
```
